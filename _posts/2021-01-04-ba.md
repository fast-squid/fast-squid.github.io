---
layout: post
title: "Structure from Motion"
background: '/img/posts/02.jpg'
category: slam
use_math: true

---

# Structure from Motion
<figure>
<img class="img-fluid" src="/img/posts/SfM.PNG" alt="SfM">
<figcaption>Fig 1. Structure From Motion</figcaption>
</figure>
**Structure from Motion(SfM)** 이 대체 무엇일까. SLAM을 공부할때 자꾸
**Bundle Adjustment(BA)** 라는 녀석이 나오더라고요... ORB-SLAM 가 BA를 언급하면서 시작하고있기 때문에 BA를 공부해야겠다고 결심했습니다.
2차원 이미지로부터 3차원 구조를 추정하기 위한 기법인 것 같은데 ICP, NDT랑은 어떤 차이가 있는 것인지 혹은 상위 개념인지 정말 너무 헷갈리는군요!


- Problem
Given m images of n fixed 3D points, estimate the $m$ projection matrices $P\_j$ and the $n$ points $X\_j$ from the $m \dot n $ correspondences $u\_{ij} \leftrightarrow u\_{kj}$
SfM 알고리즘이 어떤 상황에서 쓰이는지 알면 좀더 이해가 쉬울지도 모르니 한번 상상해봅시다. 하찮은 영어실력으로 해석해면 이런상황인 것 같습니다.
m개의 구도에서 같은 지점을 바라볼때 각 이미지들에서 매칭되는 점들의 correspondence를 구하려고 ㅎ

위 그림에서 빨간 점군, 파란 점군을 각각 시점 $t$, $t+1$의 데이터라고 생각해봅시다. 
두 데이터는 같은 오브젝트를 관찰한 것이지만 각 시점의 센서 위치가 다르기 때문에 사실상 특별한 처리를 하지 않는 이상 두 데이터는 서로 관련이 없습니다.

위 두 데이터의 correlation 혹은 correspondence를 알기 위해서 수행하는 작업이 **Registration**입니다.
Registration을 위한 알고리즘엔 대표적으로 **ICP(Iterative Closest Point)** 와 **NDT(Normal Distribution Transform)** 이 있습니다.
오늘 포스팅에선 ICP에 대해 알아보도록 해보죠.


## Iterative Closest Point 
위 두마리의 토끼 데이터를 겹치는 작업을 **align**이라고 합니다.

로봇이나 차량 내부에 완전 무결한 센서가 있다면 Wheel odometry를 통해 시작점만 알고 있다면 현재의 Pose를 구하는 Localization이 가능할 것입니다.
하지만 실제 센서들은 센서노이즈 등의 이유로 완벽하지가 않습니다.
간단하게 예시를 들어봅시다.
$\$ \hat{z} = f(x) $\$
$\$ \hat{z} + e = z $\$
 우리가 어떤 값 $x$를 카메라로 관찰하면 $f(x)$의 Transformation 을 거쳐 $\hat{z}$을 얻게 됩니다.
 실제 $z$는 에러 $e$를 보정해야 얻을 수 있겠죠.
 $\$ e(x) = z - f(x) $\$
 그리고 Cost Function을 *e*를 정의할 수 있습니다.
 $\$ e' = e^{T} \Omega e $\$
 
 Cost function이 왜 저렇게 나오는건지는 찾아봐야겠네요...
 
아무튼 우리는 Cost를 최소화하는 것이 목적입니다. SLAM에 적용하면 $e(x)$가 최소일때의 로봇의 Pose $x^{\*}$를 구하는것이죠.
$\$ x^{\*} = argmin\sum{e(x)} $\$

### argmin
#### 5-step process
1. Linearize(Taylor expansion) the error terms around the current solution / initial guess
1. Compute the first dervative of the squared error function
1. Set derivative to zero and solve linear system
1. Obtain the new state
1. Iterate

첫째로 Cost Function을 최소화하기위해 테일러급수를 구해줍니다. 테일러급수란 어떤 함수 f(x)를 무한급수로 표현하는 것을 뜻합니다.
$\$f(x) = \sum_{k=0}^{\infty}\cfrac{f^{(k)}(a)}{k!}(x-a)^k $\$
물론 컴퓨터로 계산하기 위해서는 앞의 도함수, 2계도함수까지만 전개해줍니다.
$\$ e(x+\Delta{x}) \approx e(x+\Delta{x})+J(x) $\$
$\$ e'(x+\Delta{x}) = e^{T}(x+\Delta{x}) \Omega e(x+\Delta{x}) $\$
$\$ e'(x+\Delta{x}) \approx (e+J\Delta{x})^{T}\Omega (e+J\Delta{x}) $\$

결과적으로 얻어진 식을 전개해서 풀면 다음과 같습니다.
$\$
e'(x+\Delta{x}) \approx e^{T}\Omega e + e^{T}\Omega J \Delta{x} + \Delta{x}^{T}J^{T}\Omega{e} + \Delta{x}^{T}J^{T}\Omega{J}\Delta{x}
$\$

첫째 항은 x에 대한 식이 아니므로 C(constant)라고 두고 2,3 항은 Linearly dependent, 마지막은 Qaudratic dependency를 갖고 있습니다.
함수의 최소 혹은 최대값은 Derivate가 0일때의 값이기 때문에 미분을 해줍니다.
Constant는 없어지고 일차항의 계수를 b, 2차항의 계수를 H라 두면 다음과 같이 표현됩니다.
$\$
\cfrac{\partial{F(x+\Delta{x}}}{\partial\Delta{x}} = 2b + 2H\Delta{x} = 0
$\$
$\$ H\Delta{x} = -b $\$

여기까지 왔으면 다 끝난것이나 마찬가지죠. $H$의 역행렬을 양변에 곱하면 되니까요.
하지만 H의 역행렬이 존재하지 않을수 있습니다.
- $H$ is not a square matrix
- $Det(H) = 0$
H가 정사각행렬이 아닌경우 정사각행렬을 만들어주기 위해 다음과 같은 작업을 해줍니다.
$\$ H^{T}H\Delta{x} = -H^{T}b $\$
$\$ \Delta{x} = -(H^{T}H)^{-1}Hb $\$

이런 모든 과정은 사실 계산량이 많아 Computationally efficient 하다고 볼 수 없습니다. 이런 문제들을 해결하기 위해
**Cholesky Factorization, Conjugate Gradient** 방식을 쓴다고 하네요.
하지만 여기선 다루진 않겠습니다! 저도 잘 모르니까요!


